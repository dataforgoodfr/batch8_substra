# Compte-rendu de réunion - 30 Septembre 2020

## Présents 

Clément, Dena, Joséphine, Gijs

## Compte-rendu

- Fairness metrics : 
    
    - Un besoin de clarification / d'apporter un angle a été demandé par l'équipe 
    - _Proposition par Eric hors réunion_ 

        - Message dans slack : "Hello tous @ici ! J'espère que vous allez bien. On m'a demandé de creuser le sujet fairness pour le structurer plus précisément. Je m'y suis collé dans l'après-midi et vous propose le cadrage suivant - pour discussion bien entendu !"
            1. Lire à fond ce [tutoriel](https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb) de référence comme une synthèse de l'état de l'art vraiment bien
            1. Choisir dans la partie §5.4 un dataset qui vous motive parmi les 4 proposés
            1. À partir de votre dataset, formuler un problème de ML (un output à prédire) et un risque de biais discriminatoire (au regard de l'existence d'une ou plusieurs variable(s) protégée(s) dans les inputs). Ce peut être ceux suggérés avec les datasets, ou bien une problématique que vous définissez par vous-même
            1. Ensuite, au regard de ce problème de ML: a) élaborer un algo d'apprentissage pour entraîner un modèle prédictif et évaluer sa performance de manière classique ; b) évaluer sa fairness sur les 4 métriques de base décrites en §4.1 à §4.4
            1. Rédiger un tutoriel au format notebook avec votre code élaboré pour les points 3 et 4 ci-dessus, avec un souci de pédagogie (en incluant des liens vers des ressources complémentaires pour approfondir lorsque c'est pertinent)
            1. [complément expert] Ajouter les métriques de fairness §4.5 et/ou §4.6 au tutoriel
            1. [complément expert] Ajouter une optimisation décrite au §5.2 au tutoriel

    - Ces axes seront discutés lors de la réunion du 14/10/2020

- Généalogie de bout-en-bout 

    - Premières étapes identifiés :

        - Etudier les model cards de Google 
        - Tenter d'installer / d'utiliser les models cards
        - En fonction de ce qui est proposé, décider soit de proposer un tutoriel sur ces model cards, soit de réfléchir à uneautre approche.

- Model distillation : 

    - Tentative d'installation en cours sur un outil par Gijs. Pour le moment pas de réussite mais tentative toujours en cours. 
    - Poursuite des lectures sur le sujet
    - Proposition de rencontrer Romain Goussault qui a travaillé sur le sujet - à réaliser une fois que le sujet aura été un peu défricher 

- Robustness metrics :

    - Proposition de plan d'actions par Nathan : 

        1. Contexte du sujet
        1. Définition d'une IA de confiance selon la Com UE (et je ferais un lien vers votre référentiel)
        1. Présentation outil version technique + axes d'améliorations
        1. Présentation outil version graphique (en dev)
        1. Ambitions de l'outil
        1. Discussions pour savoir comment l'intégrer (ou non) au sein du groupe de travail

- Differential Privacy 

    - Personne ne s'est encore emparé du sujet - à voir dans un second temps 

- Misc 

    - Proposition de ne se retrouver qu'une semaine sur deux : à discuter lors du prochain atelier 
    - Proposition de présenter la démarche lors de l'atelier Data Science Responsable et de Confiance du 10 novembre - à rediscuter 
    - Présentation prévue le 14/10 de l'outil de Nathan (_on a hâte !_) 

