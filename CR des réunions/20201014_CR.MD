 Compte-rendu de réunion - 30 Septembre 2020

## Présents 

Clément, Dena, Joséphine, Nathan, Eric, Arthur

## Compte-rendu

- Présentation par Nathan de son outil TrasparentAI 

    - [Documentation](https://transparentai.readthedocs.io/en/latest/)
    - [Présentation](batch8_substra/Autres/transparentai_20201014.pdf) en PDF
    - Une approche modulaire qui couvre les différents sujets de l'UE
    - Une plateforme plus simple d'utilisation pour des profils non data scientist est en cours de développement 
    - Côté Substra Foundation : c'est une très bonne ressource que nous alons étudié en profondeur et voir comment potentiellement l'intégrer / réaliser des synergies. 

Un grand merci à Nathan pour cette présentation très intéressante ! 

- Fairness metrics :

    - Proposition d'approche par Eric :

        - 1. Lire à fond ce [tutoriel](https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb) de référence comme une synthèse de l'état de l'art vraiment bien
            1. Choisir dans la partie §5.4 un dataset qui vous motive parmi les 4 proposés
            1. À partir de votre dataset, formuler un problème de ML (un output à prédire) et un risque de biais discriminatoire (au regard de l'existence d'une ou plusieurs variable(s) protégée(s) dans les inputs). Ce peut être ceux suggérés avec les datasets, ou bien une problématique que vous définissez par vous-même
            1. Ensuite, au regard de ce problème de ML: a) élaborer un algo d'apprentissage pour entraîner un modèle prédictif et évaluer sa performance de manière classique ; b) évaluer sa fairness sur les 4 métriques de base décrites en §4.1 à §4.4
            1. Rédiger un tutoriel au format notebook avec votre code élaboré pour les points 3 et 4 ci-dessus, avec un souci de pédagogie (en incluant des liens vers des ressources complémentaires pour approfondir lorsque c'est pertinent)
            1. [complément expert] Ajouter les métriques de fairness §4.5 et/ou §4.6 au tutoriel
            1. [complément expert] Ajouter une optimisation décrite au §5.2 au tutoriel

    - Si pour des "connaisseurs", la demande est "basique", il n'y a cependant pas beaucoup de notebooks simple à prendre en main pour un data scientist non confirmé. Nous sommes persuadés côté Substra que cela aura du sens. 
    - [Exemple intéressant](https://www.kaggle.com/nathanlauga/ethics-and-ai-how-to-prevent-bias-on-ml) proposé par Nathan, totalement en lien avec ce qui est proposé. 
    - On continue d'essayer d'avancer sur le sujet... 

- Robustness metrics 

    - Pas d'avancement suplémentaire, mais validation de l'approche proposée par Nathan. 
    - Première étape : réaliser une description / article de blog sur ce qu'est la robustesse. 
    - Puis retour attendu de l'équipe pour alignement avant tentative d'implémentation.

- Model Cards 

    - Première lecture des model cards de google par Joséphine : ce n'est pas un outil / API qui permet de faire des choses simplement, mais plus un exemple (même pas un template)
    - Prochaines étapes : se pencher sur [l'article de recherche](https://arxiv.org/pdf/1810.03993.pdf) qui a servi de base pour identifier les bonnes idées 
    - Travailler sur la suite de l'approche (action Clément / Joséphine) : proposer un template ? Un outil ? 

- Distillation de modèle (_post réunion_)

    - Toujours un blocage sur l'implémentation côté Gijs, poursuite des travaux en cours
    - Ressources identifiées remontées par Romain Goussault : 
        - [Distilling the Knowledge in a Neural Network](https://arxiv.org/pdf/1503.02531.pdf)
        - [Understanding and Improving Knowledge Distillation](https://arxiv.org/pdf/2002.03532.pdf)
        - [Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results](https://arxiv.org/pdf/1703.01780.pdf)
        - [Private Federated Learning with Domain Adaptation](https://arxiv.org/pdf/1912.06733.pdf)

On continue les discussions sur Slack et la semaine prochaine au LLL ! 
