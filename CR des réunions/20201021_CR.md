Compte-rendu de réunion - 21 octobre 2020

## Présents 

Clément, Nathan, Gijs

## Compte-rendu

- Fairness metrics : 

    - Cette partie du projet connait quelques difficultés : manque de temps des participants, questionnement sur le démarche proposée (trop globale? angle d'attaque pas assez original?)
    - Pour autant, tous les participants reconnaissent le fort intérêt des fairness metrics.
    - Quelques pistes intéressantes proposées par Nathan suite au travail réalisé dans le cadre de son mémoire d'études réalisé sur les biais. 
    - Prochaines actions : Nathan va aider à poursuivre et approfondir les réflexions sur l'angle à travailler pour les fairness metrics.  

- Généalogie de bout-en-bout

    - Nouvelles ressources identifiées à étudier : 

        - (Tool) [Machine Learning Canvas](https://www.louisdorard.com/machine-learning-canvas) est une fiche Canvas servant de Framework pour cadrer un sujet de Machine Learning avec 4 sections : Goal, Learn, Predict, Evaluate. Il existe une suite d’article Medium From Data to AI with the [Machine Learning Canvas (Part I)](https://medium.com/louis-dorard/from-data-to-ai-with-the-machine-learning-canvas-part-i-d171b867b047)
        - [People AI Guidebok](https://pair.withgoogle.com/guidebook/)
    - En parallèle de l'étude de ces nouvelles ressources, proposition de démarrer la création d'un template markdown qui recense tout ce dont un data scientist a besoin de se préoccuper concernant son modèle (action Clément / Joséphine)

- Distillation de modèles 

    - Résultats des premières recherches sur le sujet de Gijs : 

        - La sujet est vraiment à l'état de recherche : pas de librairies simples à utiliser (uniquement des outils complexes en PyTorch), pas de vulgarisation mais des articles de recherche pointus
        - La distillation de modèles est le plus souvent abordée sous l'angle de la recherche de performance ou d'optimisation de la taille du modèle, et assez peu sous l'angle de la protection des attaques par inférence. 
        - Quelques ressources intéresantes identifiées :

            - [DistilBERT](https://arxiv.org/abs/1910.01108), a distilled version of BERT: smaller, faster, cheaper and lighter
            - [Adversarial Robustness Toolbox (ART) v1.4](https://github.com/Trusted-AI/adversarial-robustness-toolbox) (sur la compréhension des attaques par inférence)
        - Etant donné la complexité du sujet, il semble qu'un article de blog présentant la distillation de modèle soit plus envisageable à ce state qu'un notebook technique complexe à mettre en place. 
    - Prochaines actions (Gijs): 

        - Revue des différentes ressources identifiées
        - Rencontre à planifier avec Romain Goussault de Substra Foundation pour discuter des sujets 
 
- Robustness metrics 

    - Le sujet est vaste et une première étape en cours est de définir ce qu'est la robustesse. Cette définition sera soumise à discussion. 
    - Certains sujets / prises de positions seront soumis à réflexion lors de l'atelier Data Science Responsable et de Confiance. Exemple : l'apprentissage en continue doit il être évité ? 

- Points divers : 

    - Changement d'outil de Basecamp vers Trello car peu pratique + période d'essaie peu concluante (action Clément)
    - Invitation des membres du projet à l'Atelier Data Science responsable et de confiance pour présenter la démarche / premières pistes de réflexions de Data For Good
    - Essayer de trouver comment lier les sujets / raconter une histoire à parti des différents sujets.

Merci à tous et à très vite ! 